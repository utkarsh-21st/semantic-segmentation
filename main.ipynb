{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Video (and Image) segmentaion using DeepLab-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requisite Packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image-objects which the model is capable of performing segmentation on\n",
    "LABELS = ['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "          'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "          'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tv']\n",
    "\n",
    "# dict, represent each label with an integer\n",
    "encodings = {v: k for k, v in enumerate(LABELS)}\n",
    "\n",
    "class DeepLabModel(object):\n",
    "    \"\"\"Class to load deeplab model and run inference.\"\"\"\n",
    "\n",
    "    INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
    "    OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
    "    INPUT_SIZE = 513\n",
    "\n",
    "    def __init__(self, frozen_graph):\n",
    "        \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n",
    "        self.graph = tf.Graph()\n",
    "    \n",
    "        with tf.io.gfile.GFile(frozen_graph, 'rb') as f:\n",
    "            graph_def = tf.compat.v1.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "\n",
    "        if graph_def is None:\n",
    "            raise RuntimeError('Cannot find inference graph in tar archive.')\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "        self.sess = tf.compat.v1.Session(graph=self.graph)\n",
    "\n",
    "    def run(self, image):\n",
    "        \"\"\"Runs inference on a single image.\n",
    "\n",
    "        Args:\n",
    "          image: A numpy array, raw input image.\n",
    "\n",
    "        Returns:\n",
    "          resized_image: RGB image resized from original input image.\n",
    "          seg_map: Segmentation map of `resized_image`.\"\"\"\n",
    "        width, height = image.shape[1::-1]\n",
    "        resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
    "        target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
    "        resized_image = cv.resize(image, target_size, interpolation=cv.INTER_AREA)\n",
    "        batch_seg_map = self.sess.run(\n",
    "            self.OUTPUT_TENSOR_NAME,\n",
    "            feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n",
    "        seg_map = batch_seg_map[0]\n",
    "        return resized_image, seg_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmented(image, interest_labels_encoded):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image: numpy array, RGB format   \n",
    "\n",
    "    Returns: \n",
    "        resized-segmented-image(nd array)\n",
    "    \"\"\"\n",
    "    resized_im, seg_map = model.run(image)\n",
    "    mask = np.isin(seg_map, interest_labels_encoded).astype('uint8')\n",
    "    segmented = cv.bitwise_and(resized_im, resized_im, mask=mask)\n",
    "    return segmented\n",
    "\n",
    "def on_image(path, interest_labels):\n",
    "    '''\n",
    "    Args:\n",
    "        path: image path with extension(jpg/png)\n",
    "        interest_labels: list of labels which you want the model to identify\n",
    "        \n",
    "    Returns: \n",
    "        Saves the segmented-image to the current directory\n",
    "    '''\n",
    "    interest_labels_encoded = [encodings[n] for n in interest_labels]\n",
    "    image = cv.imread(path)\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB) \n",
    "    segmented = get_segmented(image, interest_labels_encoded)\n",
    "    segmented = cv.cvtColor(segmented, cv.COLOR_RGB2BGR) \n",
    "    cv.imwrite('segmented.jpg', segmented)\n",
    "    print('Done!')\n",
    "    \n",
    "def on_video(path, interest_labels, fps=30, codec='XVID'):\n",
    "    '''\n",
    "    Args:\n",
    "        path: video path with extension(mp4, etc)\n",
    "        interest_labels: list of labels which you want the model to identify\n",
    "        fps: desired FPS(Frames Per Second)\n",
    "    \n",
    "    Saves the segmented-video to the current directory\n",
    "    '''\n",
    "    interest_labels_encoded = [encodings[n] for n in interest_labels]\n",
    "    cap = cv.VideoCapture(path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        segmented = get_segmented(frame, interest_labels_encoded)\n",
    "        dimensions = segmented.shape\n",
    "        break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    cap = cv.VideoCapture(path)\n",
    "    fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv.VideoWriter('segmented.mp4', fourcc, 30, dimensions[:2][::-1])\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Done!\")\n",
    "            break\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB) # conversion because get_segmented() expects RGB\n",
    "        segmented = get_segmented(frame, interest_labels_encoded)\n",
    "        segmented = cv.cvtColor(segmented, cv.COLOR_RGB2BGR) # conversion because write() expects BGR\n",
    "        out.write(segmented)\n",
    "        \n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model into the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose any one (Download links in readme file)\n",
    "# mobilenetv2 as backbone, Small size, relatively low accuracy\n",
    "# frozen_graph = 'deeplabv3_mnv2_pascal_trainval/frozen_inference_graph.pb' \n",
    "\n",
    "# xception as backbone, large size, relatively better accuracy\n",
    "frozen_graph = 'deeplabv3_pascal_trainval/frozen_inference_graph.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = DeepLabModel(frozen_graph)\n",
    "print('model loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose interest-labels from the below list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
       "       'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse',\n",
       "       'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train',\n",
       "       'tv'], dtype='<U11')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image-object which you want the model to segment\n",
    "interest_labels = ['person', 'cow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Path of image to process\n",
    "img = 'test/img.JPG'\n",
    "\n",
    "on_image(img, interest_labels) # saves the results to currect directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Path of video to process\n",
    "vid = 'test/test.mp4'\n",
    "\n",
    "on_video(vid, interest_labels, fps=25) # saves the results to currect directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
